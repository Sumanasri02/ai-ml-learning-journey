{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLGZoltG84CLDOEKegCSF/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sumanasri02/ai-ml-learning-journey/blob/main/04_Model_Evaluation_and_Tuning/02_model_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mXiDePlmQRoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Tuning in Machine Learning\n",
        "\n",
        "## Overview\n",
        "Model tuning improves performance by adjusting hyperparameters.\n",
        "This notebook covers overfitting, underfitting,\n",
        "and hyperparameter tuning using GridSearchCV.\n",
        "## Overfitting vs Underfitting\n",
        "\n",
        "- **Underfitting**: Model is too simple and performs poorly on both train and test data\n",
        "- **Overfitting**: Model performs well on training data but poorly on unseen data\n",
        "\n",
        "Goal: Achieve good generalization.\n",
        "## Bias–Variance Tradeoff\n",
        "- **High Bias** → Underfitting\n",
        "- **High Variance** → Overfitting\n",
        "A good model balances bias and variance.\n"
      ],
      "metadata": {
        "id": "laPsyP-HT-J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n"
      ],
      "metadata": {
        "id": "Czmsp3LQUTqh"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters\n",
        "Hyperparameters are values set before training\n",
        "that control the learning process.\n",
        "\n",
        "Example:\n",
        "- learning rate\n",
        "- number of neighbors\n",
        "- regularization strength\n"
      ],
      "metadata": {
        "id": "y_PlBfDlUzoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "X = np.array([[1], [2], [3], [4], [5], [6]])\n",
        "y = np.array([2, 4, 6, 8, 10, 12])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Model\n",
        "model = LinearRegression()\n",
        "\n",
        "# GridSearch (LinearRegression has few hyperparameters, example purpose)\n",
        "param_grid = {\n",
        "    \"fit_intercept\": [True, False]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    model,\n",
        "    param_grid,\n",
        "    scoring= \"neg_mean_squared_error\",\n",
        "    cv = 3\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiEsHvaIUv-l",
        "outputId": "4a7c7801-1235-4f5b-c2cf-d8580f3d2ffc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'fit_intercept': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(\"Tuned Model MSE:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCjPwNLXVqIJ",
        "outputId": "06127756-7821-495d-e368-cd285c4b27b0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned Model MSE: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Takeaways\n",
        "- Overfitting reduces generalization\n",
        "- Bias–variance tradeoff is central to ML\n",
        "- GridSearchCV automates hyperparameter tuning\n"
      ],
      "metadata": {
        "id": "wSv38ylCWBlt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_z89mh1hV86W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}